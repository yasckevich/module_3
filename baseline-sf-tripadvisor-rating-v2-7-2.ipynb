{"cells":[{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Немного изменим названия столбцов для удобства**"},{"metadata":{"trusted":true},"cell_type":"code","source":"col = ['Restaurant_id', 'City', 'Cuisine_Style', 'Ranking', 'Price_Range', 'Number_of_Reviews', 'Reviews', 'URL_TA', 'ID_TA','sample','Rating']\ndata.columns = col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info(100000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning and Prepping Data"},{"metadata":{},"cell_type":"markdown","source":"**Проверяем столбец с Restaurant_id (идентификационный номер ресторана / сети ресторанов)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Restaurant_id.value_counts()\n# пропусков нет, все ок\n\nprint(data.Restaurant_id.describe())\n# по условию - в одному id  могут быть прикреплены несколько ресторанов одной сети,\n# поэтому уникальных значений меньше чем записей\n\ndata.Restaurant_id = [i[3:] for i in data.Restaurant_id]\ndata.Restaurant_id = [int(i) for i in data.Restaurant_id]\n\nprint(' ')\nprint(len(data.Restaurant_id))\nprint(type(data.Restaurant_id[1]))\n\n# превратили столбец в численное выражение","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Добавляем обозначение сетевых магазинов**"},{"metadata":{"trusted":true},"cell_type":"code","source":"a=data.Restaurant_id.value_counts()\na=dict(a)\na=pd.DataFrame({'count':a}, columns=['count'])\n\nA=a.index\nB=a.values\n\ndata['chain']= data['Restaurant_id'].replace(A, B)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Проверяем столбец с City (город, в котором находится ресторан)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.City.value_counts()\n# пропусков нет, города не повторяются, проблем с ракладкой или регистром нет, все ок\n\nprint(data.City.describe())\n\nA = list(data.City.value_counts().keys())\nB = range(0, len(A))\ndict_city = dict(zip(A, B))\n# словарь со значениями городов\n\ndata['City_ind'] = data['City'].replace(A, B)\n\nprint(' ')\nprint(len(data.City_ind))\nprint(type(data.City_ind[1]))\n\n# аномалий нет + мы заменили города на числовые индефикаторы","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Сделаем \"нормализацию\" значения рейтинга по городам"},{"metadata":{"trusted":true},"cell_type":"code","source":"A = list(data.City.value_counts().keys())\ndata1=pd.DataFrame()\ndata1['City'] = data['City']\ndata1['Ranking']=data['Ranking']\ndata1=pd.DataFrame(data1.groupby(['City']).max())\ndata2=data1['Ranking']\nA=list(data2.keys())\nB=list(data2)\n\ndata['Len_rest_in_city'] = data['City'].replace(A, B)\n\ndata['Std_ranking']=data['Ranking']/data['Len_rest_in_city']\n\ndata.Std_ranking.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Добавим столбец Residents (кол-во жителей в каждом городе)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"B = [8961989, 2148271, 3266126, 1636762, 3769495, 1397852, 4110000, 1324277, 506654, 1888776, 860124,\n     179277, 1899160, 1471508, 481181, 975904, 1752286, 1790658, 1173179, 794128, 664046, 513210, 424008,\n     237591, 201818, 779115, 693491, 643272, 432862, 626108, 295504]\ndict_res = dict(zip(A, B))\n# словарь со кол-вом жителей\n\ndata['Residents'] = data['City'].replace(A, B)\n\nprint(len(data.Residents))\nprint(type(data.Residents[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Добавим столбец Country (страна)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Country'] = data.City\ndata['Country'] = data['Country'].replace('London', 'GreatBritain')\ndata['Country'] = data['Country'].replace('Paris', 'France')\ndata['Country'] = data['Country'].replace('Madrid', 'Spain')\ndata['Country'] = data['Country'].replace('Barcelona', 'Spain')\ndata['Country'] = data['Country'].replace('Berlin', 'Germany')\ndata['Country'] = data['Country'].replace('Milan', 'Italy')\ndata['Country'] = data['Country'].replace('Rome', 'Italy')\ndata['Country'] = data['Country'].replace('Prague', 'CzechRepublic')\ndata['Country'] = data['Country'].replace('Lisbon', 'Portugal')\ndata['Country'] = data['Country'].replace('Vienna', 'Austria')\ndata['Country'] = data['Country'].replace('Amsterdam', 'Netherlands')\ndata['Country'] = data['Country'].replace('Brussels', 'Belgium')\ndata['Country'] = data['Country'].replace('Hamburg', 'Germany')\ndata['Country'] = data['Country'].replace('Munich', 'Germany')\ndata['Country'] = data['Country'].replace('Lyon', 'France')\ndata['Country'] = data['Country'].replace('Stockholm', 'Sweden')\ndata['Country'] = data['Country'].replace('Budapest', 'Hungary')\ndata['Country'] = data['Country'].replace('Warsaw', 'Poland')\ndata['Country'] = data['Country'].replace('Dublin', 'Irland')\ndata['Country'] = data['Country'].replace('Copenhagen', 'Denmark')\ndata['Country'] = data['Country'].replace('Athens', 'Greece')\ndata['Country'] = data['Country'].replace('Edinburgh', 'Scotland')\ndata['Country'] = data['Country'].replace('Zurich', 'Switzeland')\ndata['Country'] = data['Country'].replace('Oporto', 'Portugal')\ndata['Country'] = data['Country'].replace('Geneva', 'Switzeland')\ndata['Country'] = data['Country'].replace('Krakow', 'Poland')\ndata['Country'] = data['Country'].replace('Oslo', 'Norway')\ndata['Country'] = data['Country'].replace('Helsinki', 'Finland')\ndata['Country'] = data['Country'].replace('Bratislava', 'Slovakia')\ndata['Country'] = data['Country'].replace('Luxembourg', 'Luxembourg')\ndata['Country'] = data['Country'].replace('Ljubljana', 'Slovenia')\n\nA = list(data.Country.value_counts().keys())\nB = range(0, len(A))\ndict_country = dict(zip(A, B))\n# словарь со значениями стран\n\n\ndata['Country_ind'] = data['Country'].replace(A, B)\n\nprint(len(data.Country_ind))\nprint(type(data.Country_ind[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Добавим столбик с отношением кол-ва отзывов к населению (как часто пишут их)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Rew_of'] = data['Number_of_Reviews']/data['Residents']\ndata['Rew_of'] = data['Rew_of'].fillna(0)\n\n\n\nprint(len(data.Rew_of))\nprint(type(data.Rew_of[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Проверяем столбец с Cuisine_Style (кухня или кухни, к которым можно отнести блюда, предлагаемые в ресторане)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['Cuisine_Style'] = data['Cuisine_Style'].fillna('\"\"No_info\"')\n# заменяем пропуски\n\nnew = pd.DataFrame(data.Cuisine_Style.dropna())\na = list(new.Cuisine_Style)\nb = list()\n\ndef l(x):\n    i = 0\n    for g in x:\n        f = x[i].split(',')\n        v = 0\n        for g in f:\n            h = f[v][2:-1].replace(\"'\", '')\n            v = +1\n            b.append(h)\n        i += 1\n        \nl(a)\n\nfrom collections import Counter\n\ncoun=Counter(b)\ncoun=dict(coun)\ncoun=pd.DataFrame({'count':coun}, columns=['count'])\na=coun['count'].mean()\n\nb=list(coun.query('count > @a').index)\nb\n\n#оставляем только самые популярные кухни\n\ndef find_item(cell):\n    if item in cell:\n        return 1\n    return 0\n\n\nfor item in b:\n    data[item] = data['Cuisine_Style'].apply(find_item)\n\ndata['Cuisine_Style'] = data['Cuisine_Style'].apply(lambda x: len(x))\n\nlen(data['Cuisine_Style'])\n# пропуски заменены, строки преобразованы в столбцы","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Проверяем столбец с Price_Range (диапазон цен в ресторане)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.Price_Range.describe())\n\ndata['Price_Range'] = data['Price_Range'].replace('$', 1)\ndata['Price_Range'] = data['Price_Range'].replace('$$ - $$$', 2)\ndata['Price_Range'] = data['Price_Range'].replace('$$$$', 3)\n\na = data['Price_Range'].mean()\na = int(a)\ndata['Price_Range'] = data['Price_Range'].fillna(a)\n\nprint('')\nprint(len(data.Price_Range))\nprint(type(data.Price_Range[1]))\n# заменили буквенные индефикаторы на численные","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Проверяем столбец с Reviews (данные о двух отзывах, которые отображаются на сайте ресторана)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.Reviews.describe())\n\nfrom datetime import datetime, date, time\ndata['Reviews'] = data.Reviews.replace(\"[[], []]\", 'No_info')\n# заменяем пропуски\n\ndata['Last_rew'] = data['Reviews']\n\ndata['Last_rew']=data['Last_rew'].str[-27:-17]\n\nnow = datetime.now()\n\n#base['Last_rew'][base.Last_rew.str.contains(\"]\")]=now\ndata['Last_rew'][data.Last_rew.str.contains(\"]\")==True] = now\ndata['Last_rew'] = data['Last_rew'].fillna(now)\n\n# приравниваем строки без даты к сегодня\n\ndata['Last_rew'] = [pd.to_datetime(i) for i in data.Last_rew]\n\n# добавляем сколько прошло времени с момента последнего отзыва\n\ndata['Last_rew_data'] = data['Last_rew']-now\ndata['Last_rew_data'] = [i.total_seconds() for i in data.Last_rew_data]\ndata['Last_rew_data'] = data['Last_rew_data']\ndata['Last_rew_data'] = data['Last_rew_data'].fillna(0)\n\n\n\nprint('')\nprint(len(data.Last_rew_data))\nprint(type(data.Last_rew_data[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Проверяем столбец с Number_of_Reviews (количество отзывов о ресторане)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime, date, time\n\nm=data['Number_of_Reviews'].mean()\n\nprint(data['Number_of_Reviews'].describe())\n# отрицательных чисел нет\n\ndata['Number_of_Reviews'].value_counts()\n# но есть пропуски, нужно проверить, что где есть пропуски - там действительно нет отзывов\n\ndata['Number_of_Reviews'] = data['Number_of_Reviews'].fillna('No_info')\n# меняем пропуски на Not_info\n\na = data.query('Reviews == \"No_info\" & Number_of_Reviews == \"No_info\"')\nb = list(a.index)\ndata['Number_of_Reviews'][b] = 0\n# где нет значения кол-ва отзывов и превью отзывов - ставим 0\n\nlen(data['Number_of_Reviews'])\n# заменили предполагаемые пропуски, в некоторые смогли подставить значения. С 2,5+ тысяч снизили пропуски до 900+\n\ndata['Number_of_Reviews'] = data['Price_Range'].replace('No_info', m)\n\n# пропуски, которые не смогли заполнить, заполняем средним значением\n\n#data.Number_of_Reviews = [float(i) for i in data.Number_of_Reviews]\n\nprint('')\nprint(len(data.Number_of_Reviews))\nprint(type(data.Number_of_Reviews[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Добавляем столбик с отношением кол-ва отзывов по одному ресторану к общему кол-ву отзывов по городу**"},{"metadata":{"trusted":true},"cell_type":"code","source":"A = list(data.City.value_counts().keys())\ndata1=pd.DataFrame()\ndata1['City'] = data['City']\ndata1['Number_of_Reviews']=data['Number_of_Reviews']\n\ndata1=pd.DataFrame(data1.groupby(['City']).sum())\ndata2=data1['Number_of_Reviews']\nA=list(data2.keys())\nB=list(data2)\n\n\n\ndata['Len_rew'] = data['City'].replace(A, B)\n\ndata['Std_num_rew']=data['Number_of_Reviews']/data['Len_rew']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**проверяем м столбец с ID_TA (идентификатор ресторана в базе данных TripAdvisor)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data['ID_TA'].describe())\n\ndata['ID_TA']=data['ID_TA'].str[1:]\ndata.ID_TA = [float(i) for i in data.ID_TA]\n\nprint('')\nprint(len(data.ID_TA))\nprint(type(data.ID_TA[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,7)\ndf_train['Ranking'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['City'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотрим на топ 10 городов\nfor x in (df_train['City'].value_counts())[0:10].index:\n    df_train['Ranking'][df_train['City'] == x].hist(bins=100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Rating'].value_counts(ascending=True).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной относительно признака"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] == 5].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] < 4].hist(bins=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(data[col].drop(['sample'], axis=1).corr(),)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"**Удалим все ненужные или неполезные столбики, которые портят нам результат**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop('URL_TA', axis=1)\ndata = data.drop('Reviews', axis=1)\ndata = data.drop('Last_rew', axis=1)\ndata = data.drop('City', axis=1)\ndata = data.drop('Country', axis=1)\ndata = data.drop('Restaurant_id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data = data.drop('Len_rest_in_city', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop('chain', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop('Cuisine_Style', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(data.drop(['sample'], axis=1).corr(),)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.display.max_info_columns \ndata.info(verbose=True, max_cols=False, null_counts=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)\ntest_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sample_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)\n\nlen(predict_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def round_nearest(x, a):\n    return round(x / a) * a\n\nsample_submission['Rating'] = predict_submission.round(1)\nsample_submission['Rating'] = round_nearest(sample_submission['Rating'], 0.5)\n\n\nsample_submission.head(10)\n\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}